# í—¬ì±„ë„ ìë™ ì¶”ì²œ ì›¹ ëŒ€ì‹œë³´ë“œ (Streamlit)
import pandas as pd
import streamlit as st
import requests
from bs4 import BeautifulSoup

# ì±„ë„ ì´ë¦„ì— ë”°ë¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
def categorize_channel(name):
    if "ë²¨ë§ˆì´ì–´" in name:
        return "ë²¨ë§ˆì´ì–´ êµ¬ì—­"
    elif "ì§€ë²¤" in name:
        return "ì§€ë²¤ êµ¬ì—­"
    elif "ë°±í•´" in name:
        return "ë°±í•´ êµ¬ì—­"
    elif "ë§ˆê³„" in name:
        return "ë§ˆê³„ êµ¬ì—­"
    elif "ì¤‘ì²œ" in name:
        return "ì¤‘ì²œ êµ¬ì—­"
    else:
        return "ê¸°íƒ€"

# ìë™ í¬ë¡¤ë§ í•¨ìˆ˜ - ì˜ˆì‹œ: DFGEAR ë“í…œ ê²Œì‹œíŒ íŒŒì‹± (êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì • í•„ìš”)
def crawl_dfgear():
    url = "https://dfgear.kr/bbs/board.php?bo_table=drop"  # ì˜ˆì‹œ ì£¼ì†Œ
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)

    if response.status_code != 200:
        st.warning("DFGEARì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!!")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    items = soup.select(".wr-list tr")

    result = []
    keywords = ["ì¤‘ì²œ", "ë§ˆê³„", "ë°±í•´", "ë²¨ë§ˆì´ì–´", "ì§€ë²¤"]

    for item in items:
        tds = item.select("td")
        if len(tds) < 4:
            continue
        title = tds[1].text.strip()
        for keyword in keywords:
            if keyword in title:
                parts = title.split()
                for part in parts:
                    if "Ch." in part:
                        ì±„ë„ = f"{keyword} {part}"
                        ì¥ë¹„ = parts[-1] if len(parts) > 1 else "ë¯¸í™•ì¸"
                        ì¹´í…Œê³ ë¦¬ = categorize_channel(ì±„ë„)
                        result.append({"ì±„ë„": ì±„ë„, "ì¥ë¹„": ì¥ë¹„, "ì¹´í…Œê³ ë¦¬": ì¹´í…Œê³ ë¦¬})
    return result

def get_hot_channels(data):
    df = pd.DataFrame(data)
    channel_counts = df["ì±„ë„"].value_counts()
    gear_counts = df.groupby("ì±„ë„")["ì¥ë¹„"].apply(list)
    categories = df.drop_duplicates("ì±„ë„").set_index("ì±„ë„")["ì¹´í…Œê³ ë¦¬"]

    result = pd.DataFrame({
        "ë“í…œ ìˆ˜": channel_counts,
        "ë“œëëœ ì¥ë¹„ ëª©ë¡": gear_counts,
        "ì¹´í…Œê³ ë¦¬": categories
    }).reset_index().rename(columns={"index": "ì±„ë„"})

    result.sort_values(by="ë“í…œ ìˆ˜", ascending=False, inplace=True)
    result.reset_index(drop=True, inplace=True)
    return result

# Streamlit ì›¹ ì•± ì‹œì‘
st.set_page_config(page_title="í—¬ì±„ë„ ìë™ ì¶”ì²œ", layout="wide")
st.title("ğŸ”¥ ë˜íŒŒ íƒœì´ˆ í—¬ì±„ë„ ìë™ ì¶”ì²œ ì‹œìŠ¤í…œ")

st.markdown("""
    **ì‹¤ì‹œê°„ ë“í…œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ í•«í•œ í—¬ ì±„ë„ì„ ì¶”ì²œí•©ë‹ˆë‹¤!!**

    > DFGEAR, ë””ì‹œíŒŒ ì¸ì¦ê¸€, ë˜íŒŒ ê³µì‹ ì»¤ë®¤ë‹ˆí‹° ë“±ì—ì„œ íƒœì´ˆ ë“í…œ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ì§‘í•´ì„œ ìë™ ì¶”ì²œí•©ë‹ˆë‹¤!!
""")

# í¬ë¡¤ë§ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
data = crawl_dfgear()

# ê²°ê³¼ ì¶œë ¥
if data:
    result = get_hot_channels(data)
    st.dataframe(result, use_container_width=True)

    # í•«í•œ ì±„ë„ ê°•ì¡° ì¶œë ¥
    if not result.empty:
        top_channel = result.iloc[0]
        st.success(f"ğŸ¯ ì§€ê¸ˆ ê°€ì¥ í•«í•œ ì±„ë„ì€ **{top_channel['ì±„ë„']}** ì…ë‹ˆë‹¤! ë“œë ìˆ˜: {top_channel['ë“í…œ ìˆ˜']}ê°œ")
else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!!")
